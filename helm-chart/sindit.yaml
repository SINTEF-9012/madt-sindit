---
# Source: sindit/charts/influxdb/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: sindit-influxdb
  namespace: "gaia"
  labels:
    app.kubernetes.io/name: influxdb
    helm.sh/chart: influxdb-5.4.2
    app.kubernetes.io/instance: sindit
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: influxdb
  annotations:
automountServiceAccountToken: true
---
# Source: sindit/charts/minio/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: sindit-minio
  namespace: "gaia"
  labels:
    app.kubernetes.io/name: minio
    helm.sh/chart: minio-11.10.2
    app.kubernetes.io/instance: sindit
    app.kubernetes.io/managed-by: Helm
automountServiceAccountToken: true
secrets:
  - name: sindit-minio
---
# Source: sindit/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: sindit
  labels:
    helm.sh/chart: sindit-0.0.1
    app.kubernetes.io/name: sindit
    app.kubernetes.io/instance: sindit
    app.kubernetes.io/version: "2.0.0"
    app.kubernetes.io/managed-by: Helm
---
# Source: sindit/charts/influxdb/templates/secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: sindit-influxdb
  namespace: "gaia"
  labels:
    app.kubernetes.io/name: influxdb
    helm.sh/chart: influxdb-5.4.2
    app.kubernetes.io/instance: sindit
    app.kubernetes.io/managed-by: Helm
type: Opaque
data:
  admin-user-password: "Y3lZWEUza0wzSg=="
  admin-user-token: "S2ZoZTRkTGVwblU0WVh2U1Z5VU8="
  user-password: "d0o3QThOQVJPaw=="
---
# Source: sindit/charts/minio/templates/secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: sindit-minio
  namespace: "gaia"
  labels:
    app.kubernetes.io/name: minio
    helm.sh/chart: minio-11.10.2
    app.kubernetes.io/instance: sindit
    app.kubernetes.io/managed-by: Helm
type: Opaque
data:
  root-user: "c2luZGlkdA=="
  root-password: "UmREVFYycDBDeA=="
  key.json: ""
---
# Source: sindit/charts/neo4j-standalone/templates/neo4j-auth.yaml
apiVersion: v1
kind: Secret
metadata:
  name: "neo4j-auth"
  namespace: "gaia"
  labels:
    app: "neo4j"    
type: Opaque
data:
  NEO4J_AUTH: "bmVvNGovZ2cwdlQzSGIzNHdDZ3A="
---
# Source: sindit/charts/neo4j-standalone/templates/neo4j-config.yaml
# Neo4j config values that are required for neo4j to work correctly in Kubernetes, these are not overridden by user-provided values
apiVersion: v1
kind: ConfigMap
metadata:
  name: "sindit-k8s-config"
  namespace: "gaia"
  labels:
    app: "neo4j"    
data:
  dbms.default_listen_address: "0.0.0.0"
---
# Source: sindit/charts/neo4j-standalone/templates/neo4j-config.yaml
# User-provided Neo4j config values
apiVersion: v1
kind: ConfigMap
metadata:
  name: "sindit-user-config"
  namespace: "gaia"
  labels:
    app: "neo4j"    
data:
  dbms.config.strict_validation: "false"
  dbms.jvm.additional: |-  
    -XX:+UseG1GC
    -XX:-OmitStackTraceInFastThrow
    -XX:+AlwaysPreTouch
    -XX:+UnlockExperimentalVMOptions
    -XX:+TrustFinalNonStaticFields
    -XX:+DisableExplicitGC
    -XX:MaxInlineLevel=15
    -XX:-UseBiasedLocking
    -Djdk.nio.maxCachedBufferSize=262144
    -Dio.netty.tryReflectionSetAccessible=true
    -Djdk.tls.ephemeralDHKeySize=2048
    -Djdk.tls.rejectClientInitiatedRenegotiation=true
    -XX:FlightRecorderOptions=stackdepth=256
    -XX:+UnlockDiagnosticVMOptions
    -XX:+DebugNonSafepoints
    -Dlog4j2.disable.jmx=true
---
# Source: sindit/charts/neo4j-standalone/templates/neo4j-config.yaml
# Default Neo4j config values, these are overridden by user-provided values in sindit-user-config
apiVersion: v1
kind: ConfigMap
metadata:
  name: "sindit-default-config"
  namespace: "gaia"
  labels:
    app: "neo4j"    
data:

  # Neo4j defaults
  dbms.tx_state.memory_allocation: ON_HEAP
  dbms.connector.bolt.enabled: 'true'
  dbms.connector.http.enabled: 'true'
  dbms.connector.https.enabled: 'false'
  dbms.tx_log.rotation.retention_policy: 1 days
  dbms.windows_service_name: neo4j

  # Helm defaults
  dbms.mode: "SINGLE"

  # Bolt keep alive
  # this helps to ensure that LoadBalancers do not close bolt connections that are in use but appear idle
  dbms.connector.bolt.connection_keep_alive: "30s"
  dbms.connector.bolt.connection_keep_alive_for_requests: "ALL"
  dbms.connector.bolt.connection_keep_alive_streaming_scheduling_interval: "30s"

  # If we set default advertised address it over-rides the bolt address used to populate the browser in a really annoying way
  # dbms.default_advertised_address: "$(bash -c 'echo ${SERVICE_DOMAIN}')"


  # Other
  dbms.logs.user.stdout_enabled: "false"
  unsupported.dbms.ssl.system.ignore_dot_files: "true"
  # Logging
  dbms.directories.logs: "/logs"
  # Import
  dbms.directories.import: "/import"

  # Use more reliable defaults SSL / TLS settings for K8s
  dbms.ssl.policy.bolt.client_auth: "NONE"
  dbms.ssl.policy.https.client_auth: "NONE"
---
# Source: sindit/charts/neo4j-standalone/templates/neo4j-env.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: "sindit-env"
  namespace: "gaia"
  labels:
    app: "neo4j"    
data:
  # It should not be necessary for neo4j users/administrators to modify this configMap
  # Neo4j configuration is set in the sindit-user-config ConfigMap
  NEO4J_ACCEPT_LICENSE_AGREEMENT: "yes"
  NEO4J_EDITION: "COMMUNITY_K8S"
  NEO4J_CONF: "/config/"
  K8S_NEO4J_NAME: "neo4j"
  EXTENDED_CONF: "yes"
---
# Source: sindit/charts/influxdb/templates/pvc.yaml
kind: PersistentVolumeClaim
apiVersion: v1
metadata:
  name: sindit-influxdb
  namespace: "gaia"
  labels:
    app.kubernetes.io/name: influxdb
    helm.sh/chart: influxdb-5.4.2
    app.kubernetes.io/instance: sindit
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: influxdb
spec:
  accessModes:
    - "ReadWriteOnce"
  resources:
    requests:
      storage: "32Gi"
---
# Source: sindit/charts/minio/templates/pvc.yaml
kind: PersistentVolumeClaim
apiVersion: v1
metadata:
  name: sindit-minio
  namespace: "gaia"
  labels:
    app.kubernetes.io/name: minio
    helm.sh/chart: minio-11.10.2
    app.kubernetes.io/instance: sindit
    app.kubernetes.io/managed-by: Helm
spec:
  accessModes:
    - "ReadWriteOnce"
  resources:
    requests:
      storage: "8Gi"
---
# Source: sindit/charts/influxdb/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: sindit-influxdb
  namespace: "gaia"
  labels:
    app.kubernetes.io/name: influxdb
    helm.sh/chart: influxdb-5.4.2
    app.kubernetes.io/instance: sindit
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: influxdb
spec:
  type: ClusterIP
  sessionAffinity: None
  ports:
    - port: 8086
      targetPort: http
      protocol: TCP
      name: http
      nodePort: null
    - port: 8088
      targetPort: rpc
      protocol: TCP
      name: rpc
      nodePort: null
  selector:
    app.kubernetes.io/name: influxdb
    app.kubernetes.io/instance: sindit
    app.kubernetes.io/component: influxdb
---
# Source: sindit/charts/minio/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: sindit-minio
  namespace: "gaia"
  labels:
    app.kubernetes.io/name: minio
    helm.sh/chart: minio-11.10.2
    app.kubernetes.io/instance: sindit
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - name: minio-api
      port: 9000
      targetPort: minio-api
      nodePort: null
    - name: minio-console
      port: 9001
      targetPort: minio-console
      nodePort: null
  selector:
    app.kubernetes.io/name: minio
    app.kubernetes.io/instance: sindit
---
# Source: sindit/charts/neo4j-standalone/templates/neo4j-loadbalancer.yaml
# Service for applications that need access to neo4j
apiVersion: v1
kind: Service
metadata:
  name: "sindit-neo4j"
  namespace: "gaia"
  labels:
    helm.neo4j.com/neo4j.name: "neo4j"
    app: "neo4j"
    helm.neo4j.com/service: "neo4j"    
spec:
  type: "ClusterIP"
  
  sessionAffinity: None
  ports:
    - protocol: TCP
      port: 7474
      targetPort: 7474
      name: http
    - protocol: TCP
      port: 7473
      targetPort: 7473
      name: https
    - protocol: TCP
      port: 7687
      targetPort: 7687
      name: tcp-bolt
    
    
  selector:
    app: neo4j
    helm.neo4j.com/instance: sindit
---
# Source: sindit/charts/neo4j-standalone/templates/neo4j-svc.yaml
# ClusterIP service for bolt / http connections
apiVersion: v1
kind: Service
metadata:
  name: "sindit"
  namespace: "gaia"
  labels:
    helm.neo4j.com/neo4j.name: "neo4j"
    app: "neo4j"
    helm.neo4j.com/instance: "sindit"
    helm.neo4j.com/service: "default"    
spec:
  publishNotReadyAddresses: false
  type: ClusterIP
  selector:
    app: "neo4j"
    helm.neo4j.com/instance: "sindit"
  ports:
    - protocol: TCP
      port: 7687
      targetPort: 7687
      name: tcp-bolt
    - protocol: TCP
      port: 7474
      targetPort: 7474
      name: tcp-http
    - protocol: TCP
      port: 7473
      targetPort: 7473
      name: tcp-https
---
# Source: sindit/charts/neo4j-standalone/templates/neo4j-svc.yaml
# ClusterIP service for admin connections to Neo4j inside Kubernetes.
apiVersion: v1
kind: Service
metadata:
  name: "sindit-admin"
  namespace: "gaia"
  labels:
    helm.neo4j.com/neo4j.name: "neo4j"
    app: "neo4j"
    helm.neo4j.com/instance: "sindit"
    helm.neo4j.com/service: "admin"    
spec:
  publishNotReadyAddresses: true
  type: "ClusterIP"
  selector:
    app: "neo4j"
    helm.neo4j.com/instance: "sindit"
  ports:
    - protocol: TCP
      port: 6362
      targetPort: 6362
      name: tcp-backup
    - protocol: TCP
      port: 7687
      targetPort: 7687
      name: tcp-bolt
    - protocol: TCP
      port: 7474
      targetPort: 7474
      name: tcp-http
    - protocol: TCP
      port: 7473
      targetPort: 7473
      name: tcp-https
---
# Source: sindit/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: sindit
  labels:
    helm.sh/chart: sindit-0.0.1
    app.kubernetes.io/name: sindit
    app.kubernetes.io/instance: sindit
    app.kubernetes.io/version: "2.0.0"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 80
      targetPort: http
      protocol: TCP
      name: http
  selector:
    app.kubernetes.io/name: sindit
    app.kubernetes.io/instance: sindit
---
# Source: sindit/charts/influxdb/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: sindit-influxdb
  namespace: "gaia"
  labels:
    app.kubernetes.io/name: influxdb
    helm.sh/chart: influxdb-5.4.2
    app.kubernetes.io/instance: sindit
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: influxdb
spec:
  replicas: 1
  strategy:
    type: RollingUpdate
  selector:
    matchLabels:
      app.kubernetes.io/name: influxdb
      app.kubernetes.io/instance: sindit
      app.kubernetes.io/component: influxdb
  template:
    metadata:
      labels:
        app.kubernetes.io/name: influxdb
        helm.sh/chart: influxdb-5.4.2
        app.kubernetes.io/instance: sindit
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/component: influxdb
    spec:
      
      affinity:
        podAffinity:
          
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/name: influxdb
                    app.kubernetes.io/instance: sindit
                    app.kubernetes.io/component: influxdb
                namespaces:
                  - "gaia"
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity:
          
      priorityClassName: ""
      securityContext:
        fsGroup: 1001
      serviceAccountName: sindit-influxdb
      initContainers:
      containers:
        - name: influxdb
          image: docker.io/bitnami/influxdb:2.4.0-debian-11-r5
          imagePullPolicy: "IfNotPresent"
          securityContext:
            runAsNonRoot: true
            runAsUser: 1001
          env:
            - name: BITNAMI_DEBUG
              value: "false"
            - name: POD_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.podIP
            - name: INFLUXDB_HTTP_AUTH_ENABLED
              value: "true"
            - name: INFLUXDB_CREATE_USER_TOKEN
              value: "yes"
            - name: INFLUXDB_ADMIN_USER
              value: "admin"
            - name: INFLUXDB_ADMIN_USER_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: sindit-influxdb
                  key: admin-user-password
            - name: INFLUXDB_ADMIN_USER_TOKEN
              valueFrom:
                secretKeyRef:
                  name: sindit-influxdb
                  key: admin-user-token
            - name: INFLUXDB_ADMIN_BUCKET
              value: "primary"
            - name: INFLUXDB_ADMIN_ORG
              value: "primary"
            - name: INFLUXDB_USER
              value: "sindit_influxdb"
            - name: INFLUXDB_USER_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: sindit-influxdb
                  key: user-password
            - name: INFLUXDB_USER_BUCKET
              value: "sindit"
            - name: INFLUXDB_USER_ORG
              value: "sindit"
            - name: INFLUXDB_DB
              value: "sindit"
          envFrom:
          ports:
            - name: http
              containerPort: 8086
              protocol: TCP
            - name: rpc
              containerPort: 8088
              protocol: TCP
          livenessProbe:
            failureThreshold: 6
            initialDelaySeconds: 180
            periodSeconds: 45
            successThreshold: 1
            timeoutSeconds: 30
            exec:
              command:
                - bash
                - -c
                - |
                  . /opt/bitnami/scripts/libinfluxdb.sh

                  influxdb_env
                  export INFLUX_USERNAME="$INFLUXDB_ADMIN_USER"
                  export INFLUX_PASSWORD="$INFLUXDB_ADMIN_USER_PASSWORD"

                  timeout 29s influx ping --host http://$POD_IP:8086
          readinessProbe:
            failureThreshold: 6
            initialDelaySeconds: 60
            periodSeconds: 45
            successThreshold: 1
            timeoutSeconds: 30
            exec:
              command:
                - bash
                - -c
                - |
                  . /opt/bitnami/scripts/libinfluxdb.sh

                  influxdb_env
                  export INFLUX_USERNAME="$INFLUXDB_ADMIN_USER"
                  export INFLUX_PASSWORD="$INFLUXDB_ADMIN_USER_PASSWORD"

                  timeout 29s influx ping --host http://$POD_IP:8086
          resources:
            limits:
              memory: 4Gi
            requests: {}
          volumeMounts:
            - name: data
              mountPath: /bitnami/influxdb
      volumes:
        - name: data
          persistentVolumeClaim:
            claimName: sindit-influxdb
---
# Source: sindit/charts/minio/templates/standalone/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: sindit-minio
  namespace: "gaia"
  labels:
    app.kubernetes.io/name: minio
    helm.sh/chart: minio-11.10.2
    app.kubernetes.io/instance: sindit
    app.kubernetes.io/managed-by: Helm
spec:
  selector:
    matchLabels:
      app.kubernetes.io/name: minio
      app.kubernetes.io/instance: sindit
  strategy:
    type: Recreate
  template:
    metadata:
      labels:
        app.kubernetes.io/name: minio
        helm.sh/chart: minio-11.10.2
        app.kubernetes.io/instance: sindit
        app.kubernetes.io/managed-by: Helm
      annotations:
        checksum/credentials-secret: 6d303174bbcb71403c6c8f1e8cc608cc3f38851987a21a659769fa9c88cb9a79
    spec:
      
      serviceAccountName: sindit-minio
      affinity:
        podAffinity:
          
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/name: minio
                    app.kubernetes.io/instance: sindit
                namespaces:
                  - "gaia"
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity:
          
      securityContext:
        fsGroup: 1001
      containers:
        - name: minio
          image: docker.io/bitnami/minio:2022.9.7-debian-11-r4
          imagePullPolicy: "IfNotPresent"
          securityContext:
            runAsNonRoot: true
            runAsUser: 1001
          env:
            - name: BITNAMI_DEBUG
              value: "false"
            - name: MINIO_SCHEME
              value: "http"
            - name: MINIO_FORCE_NEW_KEYS
              value: "no"
            - name: MINIO_ROOT_USER
              valueFrom:
                secretKeyRef:
                  name: sindit-minio
                  key: root-user
            - name: MINIO_ROOT_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: sindit-minio
                  key: root-password
            - name: MINIO_DEFAULT_BUCKETS
              value: sindit
            - name: MINIO_BROWSER
              value: "on"
            - name: MINIO_PROMETHEUS_AUTH_TYPE
              value: "public"
            - name: MINIO_CONSOLE_PORT_NUMBER
              value: "9001"
          envFrom:
          ports:
            - name: minio-api
              containerPort: 9000
              protocol: TCP
            - name: minio-console
              containerPort: 9001
              protocol: TCP
          livenessProbe:
            httpGet:
              path: /minio/health/live
              port: minio-api
              scheme: "HTTP"
            initialDelaySeconds: 5
            periodSeconds: 5
            timeoutSeconds: 5
            successThreshold: 1
            failureThreshold: 5
          readinessProbe:
            tcpSocket:
              port: minio-api
            initialDelaySeconds: 5
            periodSeconds: 5
            timeoutSeconds: 1
            successThreshold: 1
            failureThreshold: 5
          resources:
            limits: {}
            requests: {}
          volumeMounts:
            - name: data
              mountPath: /data
      volumes:
        - name: data
          persistentVolumeClaim:
            claimName: sindit-minio
---
# Source: sindit/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: sindit
  labels:
    helm.sh/chart: sindit-0.0.1
    app.kubernetes.io/name: sindit
    app.kubernetes.io/instance: sindit
    app.kubernetes.io/version: "2.0.0"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: sindit
      app.kubernetes.io/instance: sindit
  template:
    metadata:
      labels:
        app.kubernetes.io/name: sindit
        app.kubernetes.io/instance: sindit
    spec:
      serviceAccountName: sindit
      securityContext:
        {}
      containers:
        - name: sindit-frontend
          securityContext:
            {}
          image: "nginx:2.0.0"
          imagePullPolicy: IfNotPresent
          command: ["python", "dt_frontend.py"]
          ports:
            - name: http
              containerPort: 8050
              protocol: TCP
          livenessProbe:
            httpGet:
              path: /
              port: http
          readinessProbe:
            httpGet:
              path: /
              port: http
          resources:
            limits:
              memory: 4Gi
        - name: sindit-backend
          securityContext:
            {}
          image: "nginx:2.0.0"
          imagePullPolicy: IfNotPresent
          command: ["python", "dt_backend.py"]
          ports:
            - name: http
              containerPort: 8000
              protocol: TCP
          livenessProbe:
            httpGet:
              path: /assets
              port: http
          readinessProbe:
            httpGet:
              path: /assets
              port: http
          resources:
            limits:
              memory: 6Gi
---
# Source: sindit/charts/neo4j-standalone/templates/neo4j-statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  labels:
    helm.neo4j.com/neo4j.name: "neo4j"
    helm.neo4j.com/dbms.mode: "SINGLE"
    app: "neo4j"
    helm.neo4j.com/instance: "sindit"    
  name: "sindit"
  namespace: "gaia"
spec:
  serviceName: "sindit"
  podManagementPolicy: "Parallel" # This setting means that the StatefulSet controller doesn't block applying changes until the existing Pod is READY.
  replicas: 1
  selector:
    matchLabels:
      app: "neo4j"
      helm.neo4j.com/instance: "sindit"
  template:
    metadata:
      labels:
        app: "neo4j"
        helm.neo4j.com/neo4j.name: "neo4j"
        helm.neo4j.com/dbms.mode: "SINGLE"
        helm.neo4j.com/pod_category: "neo4j-instance" # used for anti affinity rules
        helm.neo4j.com/neo4j.loadbalancer: "include"
        helm.neo4j.com/instance: "sindit"        
      annotations:
        "checksum/sindit-config": 82d9133d4429ac49c71708a7fa4b10e526ac513aa04028f3dbdb2100bc0d9427        
    spec:      
      affinity:
          podAntiAffinity:
            requiredDuringSchedulingIgnoredDuringExecution:
              - labelSelector:
                  matchLabels:
                    app: "neo4j"
                    helm.neo4j.com/pod_category: "neo4j-instance"
                topologyKey: kubernetes.io/hostname
      securityContext: 
        fsGroup: 7474
        fsGroupChangePolicy: Always
        runAsGroup: 7474
        runAsNonRoot: true
        runAsUser: 7474
      
      
      terminationGracePeriodSeconds: 3600            
      containers:
        - name: "neo4j"
          image: "neo4j:4.4.11"
          imagePullPolicy: "IfNotPresent"
          envFrom:
            - configMapRef:
                name: "sindit-env"
            - secretRef:
                name: "neo4j-auth"
          env:
            - name: HELM_NEO4J_VERSION
              value: "4.4.11"
            - name: HELM_CHART_VERSION
              value: "4.4.11"
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: SERVICE_NEO4J_ADMIN
              value: "sindit-admin.gaia.svc.cluster.local"
            - name: SERVICE_NEO4J_INTERNALS
              value: "sindit-internals.gaia.svc.cluster.local"
            - name: SERVICE_NEO4J
              value: "sindit.gaia.svc.cluster.local"
          ports:
            - containerPort: 7474
              name: http
            - containerPort: 7687
              name: bolt
            - containerPort: 7473
              name: https
            - containerPort: 6362
              name: backup
          resources:
            limits:
              cpu: 1000m
              memory: 2Gi
            requests:
              cpu: 1000m
              memory: 2Gi
          securityContext: 
              runAsGroup: 7474
              runAsNonRoot: true
              runAsUser: 7474
          volumeMounts:
            - mountPath: "/config/neo4j.conf"
              name: neo4j-conf
                                    
            - mountPath: "/backups"
              name: "data"
              subPathExpr: "backups"
            - mountPath: "/data"
              name: "data"
              subPathExpr: "data"
            - mountPath: "/import"
              name: "data"
              subPathExpr: "import"
            - mountPath: "/licenses"
              name: "data"
              subPathExpr: "licenses"
            - mountPath: "/logs"
              name: "data"
              subPathExpr: "logs/$(POD_NAME)"
            - mountPath: "/metrics"
              name: "data"
              subPathExpr: "metrics/$(POD_NAME)"            
          readinessProbe:
            tcpSocket:
              port: 7687
            failureThreshold: 20
            timeoutSeconds: 10
            periodSeconds: 5
          livenessProbe:
            tcpSocket:
              port: 7687
            failureThreshold: 40
            timeoutSeconds: 10
            periodSeconds: 5
          startupProbe:
            tcpSocket:
              port: 7687
            failureThreshold: 1000
            periodSeconds: 5
      volumes:
        - name: neo4j-conf
          projected:
            defaultMode: 0440
            sources:
              - configMap:
                  name: "sindit-default-config"
              - configMap:
                  name: "sindit-user-config"
              - configMap:
                  name: "sindit-k8s-config"
        
        
  volumeClaimTemplates: 
    - metadata:
        name: "data"
      spec:
        accessModes:
        - ReadWriteOnce
        resources:
          requests:
            storage: 10Gi
---
# Source: sindit/templates/tests/test-connection.yaml
apiVersion: v1
kind: Pod
metadata:
  name: "sindit-test-connection"
  labels:
    helm.sh/chart: sindit-0.0.1
    app.kubernetes.io/name: sindit
    app.kubernetes.io/instance: sindit
    app.kubernetes.io/version: "2.0.0"
    app.kubernetes.io/managed-by: Helm
  annotations:
    "helm.sh/hook": test
spec:
  containers:
    - name: wget
      image: busybox
      command: ['wget']
      args: ['sindit:80']
  restartPolicy: Never
